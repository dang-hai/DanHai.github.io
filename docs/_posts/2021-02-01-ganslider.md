---
layout: post
title: First Round Accept at ACM CHI'22 - GANSlider
date: 2022-02-01 15:01:35 +0300
image: '/images/chi22_logo.jpeg'
post_url: 2021-02-01-ganslider
---

I'm happy to announce that my second full paper was accepted for the CHI'22 conference during the first review round. Of course, acceptances and rejections (in-part) depend on being lucky with the reviewers, so I'm just glad that this time it worked to be in my favor. In my newest work, I take a close look at the slider interface for the control of generative models for images. While we see an increasing interest in generative tools, we still lack an in-depth understanding of how users perceive and interact with these user interfaces. 

The slider interface has been typically employed to allow users to adjust the underlying generative model, for example, to control semantic facial expressions such as smiling or frowning when editing a picture of a human face. However, the interaction with such a slider interfaces for controlling generative models for images has not been the focus of a user study from an HCI perspective yet. In particular we study how variations of the slider interface influence users interaction strategy. Using our prototype we logged each user interaction with the slider interface and conducted a detailed analysis of the observed interaction patterns. From our results we draw design suggestions for future systems that use slider interfaces for the control of generative models. Have a look at the paper linked below if you are interested in further details.

<img src="/images/ganslider_teaser.png" alt="Teaser figure" width="1024px"/>

**GANSlider: How Users Control Generative Models for Images using Multiple Sliders with and without Feedforward Information**<br>
Hai Dang<sup>1</sup>, Lukas Mecke<sup>2,3</sup>, Daniel Buschek<sup>1</sup><br>
<sup>1</sup>University of Bayreuth, <sup>2</sup>Bundeswehr University Munich, <sup>3</sup>LMU Munich<br>

<p align="justify"><b>Paper Link:</b> 
<a href="https://arxiv.org/pdf/2202.00965.pdf">Read Paper</a>


<p align="justify"><b>Abstract:</b> <i>We investigate how multiple sliders with and without feedforward visualizations influence users' control of generative models. In an online study (N=138), we collected a dataset of people interacting with a generative adversarial network (\textit{StyleGAN2}) in an image reconstruction task. We found that more control dimensions (sliders) significantly increase task difficulty and user actions. Visual feedforward partly mitigates this by enabling more goal-directed interaction. However, we found no evidence of faster or more accurate task performance. This indicates a tradeoff between feedforward detail and implied cognitive costs, such as attention. Moreover, we found that visualizations alone are not always sufficient for users to understand individual control dimensions. Our study quantifies fundamental UI design factors and resulting interaction behavior in this context, revealing opportunities for improvement in the UI design for interactive applications of generative models. We close by discussing design directions and further aspects.</i></p>

<p align="justify"><b>Video:</b> 
TBA